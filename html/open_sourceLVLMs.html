---
layout: default
title: 'Open-source LVLMs'
permalink: /open_sourceLVLMs.html
---
<style>
    .three-line-table {
        width: 100%;
        border-collapse: collapse; /* 边框合并 */
    }
    .three-line-table th, .three-line-table td {
        border: none; /* 清除单元格的默认边框 */
        padding: 8px; /* 单元格内边距 */
        text-align: left; /* 文本左对齐 */
    }
    .three-line-table thead {
        background-color: #f2f2f2; /* 表头背景色 */
    }
    .three-line-table thead tr th {
        border-bottom: 2px solid #000; /* 表头底部边框 */
        cursor: pointer;
        position: relative;
        padding-right: 20px;
    }
    .three-line-table tbody tr {
        border-bottom: 1px solid #ddd; /* 行分隔线 */
    }
    .three-line-table tbody tr:last-child {
        border-bottom: 2px solid #000; /* 最后一行的底部边框 */
    }
    th::after {
        content: ' ';
        position: absolute;
        right: 8px;
        top: 50%;
        transform: translateY(-50%);
        border: 5px solid transparent;
    }
    th.asc::after {
        border-bottom-color: #000;
    }
    th.desc::after {
        border-top-color: #000;
    }
    th:hover {
        color: #007bff; /* 标题悬停时的颜色变化 */
    }
</style>
<h1>Open-source LVLMs</h1>
<p>We benchmark 19 commonly used open-source LVLMs by single-turn Perplexity (PPL) 
    inferencer, which confines their output to options and computes the probability for 
    each option.
</p>
<h2>Results (in %) under multimodal bias (VL-Bias) evaluation</h2>
<table id="VLTable" class="three-line-table">
    <thead>
        <tr>
            <th onclick="sortTable('VLTable', 0)">$$Model$$</th>
            <th onclick="sortTable('VLTable', 1)">$$Ipss$$</th>
            <th onclick="sortTable('VLTable', 2)">$$B_{ovl}$$</th>
            <th onclick="sortTable('VLTable', 3)">$$B_{max}$$</th>
            <th onclick="sortTable('VLTable', 4)">$$Acc$$</th>
            <th onclick="sortTable('VLTable', 5)">$$\Delta Acc$$</th>
        </tr>
    </thead>
    <tbody>
        <tr>
            <td>LLaVA1.5-7B</td>
            <td>51.58</td>
            <td>1.85</td>
            <td>15.94</td>
            <td>52.15</td>
            <td>95.66</td>
        </tr>
        <tr>
            <td>LLaVA1.5-13B</td>
            <td>57.92</td>
            <td>2.91</td>
            <td>18.60</td>
            <td>59.08</td>
            <td>81.08</td>
        </tr>
        <tr>
            <td>LLaVA1.6-13B</td>
            <td>65.64</td>
            <td>3.29</td>
            <td>21.06</td>
            <td>67.70</td>
            <td>59.77</td>
        </tr>
        <tr>
            <td>MiniGPT-v2</td>
            <td>58.20</td>
            <td>2.72</td>
            <td>16.48</td>
            <td>59.74</td>
            <td>73.02</td>
        </tr>
        <tr>
            <td>mPLUG-Owl2</td>
            <td>72.59</td>
            <td>6.48</td>
            <td>34.02</td>
            <td>77.56</td>
            <td>8.84</td>
        </tr>
        <tr>
            <td>LLaMA-Adapter-v2</td>
            <td>55.31</td>
            <td>0.60</td>
            <td>7.38</td>
            <td>55.67</td>
            <td>86.16</td>
        </tr>
        <tr>
            <td>InstructBLIP</td>
            <td>74.26</td>
            <td>4.10</td>
            <td>19.94</td>
            <td>77.52</td>
            <td>14.05</td>
        </tr>
        <tr>
            <td>Otter</td>
            <td>62.68</td>
            <td>1.82</td>
            <td>9.25</td>
            <td>63.96</td>
            <td>59.11</td>
        </tr>
        <tr>
            <td>LAMM</td>
            <td>54.51</td>
            <td>1.63</td>
            <td>10.09</td>
            <td>55.24</td>
            <td>85.69</td>
        </tr>
        <tr>
            <td>Kosmos-2</td>
            <td>48.96</td>
            <td>0.22</td>
            <td>0.93</td>
            <td>49.58</td>
            <td>70.66</td>
        </tr>
        <tr>
            <td>Qwen-VL</td>
            <td>71.29</td>
            <td>4.07</td>
            <td>30.14</td>
            <td>74.27</td>
            <td>23.27</td>
        </tr>
        <tr>
            <td>InternLM-XC2</td>
            <td>72.93</td>
            <td>6.30</td>
            <td>37.32</td>
            <td>77.77</td>
            <td>9.45</td>
        </tr>
        <tr>
            <td>Shikra</td>
            <td>61.08</td>
            <td>3.40</td>
            <td>21.56</td>
            <td>63.44</td>
            <td>54.48</td>
        </tr>
        <tr>
            <td>LLaVA-RLHF</td>
            <td>61.05</td>
            <td>4.15</td>
            <td>27.57</td>
            <td>63.04</td>
            <td>71.24</td>
        </tr>
        <tr>
            <td>RLHF-V</td>
            <td>67.16</td>
            <td>6.96</td>
            <td>27.69</td>
            <td>72.34</td>
            <td>15.09</td>
        </tr>
    </tbody>
</table>
<br/>
<h2>Results (in %) under visual unimodal bias (V-Bias) evaluation</h2>
<table id="VTable" class="three-line-table">
    <thead>
        <tr>
            <th onclick="sortTable('VTable', 0)">$$Model$$</th>
            <th onclick="sortTable('VTable', 1)">$$Ipss$$</th>
            <th onclick="sortTable('VTable', 2)">$$B_{ovl}$$</th>
            <th onclick="sortTable('VTable', 3)">$$B_{max}$$</th>
            <th onclick="sortTable('VTable', 4)">$$Acc$$</th>
            <th onclick="sortTable('VTable', 5)">$$\Delta Acc$$</th>
        </tr>
    </thead>
    <tbody>
        <tr>
            <td>LLaVA1.5-7B</td>
            <td>51.67</td>
            <td>1.60</td>
            <td>11.34</td>
            <td>52.17</td>
            <td>95.62</td>
        </tr>
        <tr>
            <td>LLaVA1.5-13B</td>
            <td>58.85</td>
            <td>2.55</td>
            <td>14.44</td>
            <td>59.90</td>
            <td>79.27</td>
        </tr>
        <tr>
            <td>LLaVA1.6-13B</td>
            <td>66.65</td>
            <td>3.36</td>
            <td>17.55</td>
            <td>68.79</td>
            <td>56.72</td>
        </tr>
        <tr>
            <td>MiniGPT-v2</td>
            <td>55.30</td>
            <td>1.58</td>
            <td>7.43</td>
            <td>56.14</td>
            <td>83.97</td>
        </tr>
        <tr>
            <td>mPLUG-Owl2</td>
            <td>73.26</td>
            <td>5.77</td>
            <td>31.50</td>
            <td>77.68</td>
            <td>9.07</td>
        </tr>
        <tr>
            <td>LLaMA-Adapter-v2</td>
            <td>55.16</td>
            <td>0.42</td>
            <td>6.78</td>
            <td>55.40</td>
            <td>86.39</td>
        </tr>
        <tr>
            <td>InstructBLIP</td>
            <td>75.06</td>
            <td>3.23</td>
            <td>18.02</td>
            <td>77.61</td>
            <td>13.60</td>
        </tr>
        <tr>
            <td>Otter</td>
            <td>62.54</td>
            <td>1.48</td>
            <td>8.46</td>
            <td>63.56</td>
            <td>60.38</td>
        </tr>
        <tr>
            <td>LAMM</td>
            <td>57.54</td>
            <td>0.62</td>
            <td>4.33</td>
            <td>57.94</td>
            <td>77.85</td>
        </tr>
        <tr>
            <td>Kosmos-2</td>
            <td>48.95</td>
            <td>0.21</td>
            <td>0.95</td>
            <td>49.53</td>
            <td>72.69</td>
        </tr>
        <tr>
            <td>Qwen-VL</td>
            <td>71.07</td>
            <td>4.54</td>
            <td>29.88</td>
            <td>74.36</td>
            <td>23.99</td>
        </tr>
        <tr>
            <td>InternLM-XC2</td>
            <td>72.53</td>
            <td>7.24</td>
            <td>37.80</td>
            <td>78.05</td>
            <td>8.09</td>
        </tr>
        <tr>
            <td>Shikra</td>
            <td>60.23</td>
            <td>2.10</td>
            <td>14.40</td>
            <td>61.66</td>
            <td>63.15</td>
        </tr>
        <tr>
            <td>LLaVA-RLHF</td>
            <td>62.50</td>
            <td>3.01</td>
            <td>14.36</td>
            <td>64.00</td>
            <td>68.89</td>
        </tr>
        <tr>
            <td>RLHF-V</td>
            <td>63.83</td>
            <td>10.46</td>
            <td>33.05</td>
            <td>71.30</td>
            <td>19.02</td>
        </tr>
    </tbody>
</table>
<br/>
<h2>Results (in %) under language unimodal bias (L-Bias) evaluation</h2>
<table id="LTable" class="three-line-table">
    <thead>
        <tr>
            <th onclick="sortTable('LTable', 0)">$$Model$$</th>
            <th onclick="sortTable('LTable', 1)">$$Ipss$$</th>
            <th onclick="sortTable('LTable', 2)">$$B_{ovl}$$</th>
            <th onclick="sortTable('LTable', 3)">$$B_{max}$$</th>
            <th onclick="sortTable('LTable', 4)">$$Acc$$</th>
            <th onclick="sortTable('LTable', 5)">$$\Delta Acc$$</th>
        </tr>
    </thead>
    <tbody>
        <tr>
            <td>LLaVA1.5-7B</td>
            <td>50.86</td>
            <td>1.25</td>
            <td>12.08</td>
            <td>51.27</td>
            <td>97.43</td>
          </tr>
          <tr>
            <td>LLaVA1.5-13B</td>
            <td>55.86</td>
            <td>1.65</td>
            <td>14.60</td>
            <td>56.41</td>
            <td>86.85</td>
          </tr>
          <tr>
            <td>LLaVA1.6-13B</td>
            <td>62.52</td>
            <td>2.37</td>
            <td>17.35</td>
            <td>63.93</td>
            <td>69.94</td>
          </tr>
          <tr>
            <td>MiniGPT-v2</td>
            <td>54.84</td>
            <td>2.05</td>
            <td>13.48</td>
            <td>55.95</td>
            <td>84.63</td>
          </tr>
          <tr>
            <td>mPLUG-Owl2</td>
            <td>70.37</td>
            <td>4.75</td>
            <td>22.58</td>
            <td>73.92</td>
            <td>11.45</td>
          </tr>
          <tr>
            <td>LLaMA-Adapter-v2</td>
            <td>51.72</td>
            <td>0.34</td>
            <td>2.22</td>
            <td>51.91</td>
            <td>95.45</td>
          </tr>
          <tr>
            <td>InstructBLIP</td>
            <td>71.83</td>
            <td>3.41</td>
            <td>16.94</td>
            <td>74.42</td>
            <td>19.54</td>
          </tr>
          <tr>
            <td>Otter</td>
            <td>59.71</td>
            <td>0.93</td>
            <td>4.65</td>
            <td>60.36</td>
            <td>68.99</td>
          </tr>
          <tr>
            <td>LAMM</td>
            <td>56.13</td>
            <td>0.91</td>
            <td>3.72</td>
            <td>56.67</td>
            <td>80.50</td>
          </tr>
          <tr>
            <td>Kosmos-2</td>
            <td>49.94</td>
            <td>0.03</td>
            <td>0.14</td>
            <td>49.99</td>
            <td>74.55</td>
          </tr>
          <tr>
            <td>Qwen-VL</td>
            <td>70.18</td>
            <td>2.96</td>
            <td>19.94</td>
            <td>72.35</td>
            <td>18.48</td>
          </tr>
          <tr>
            <td>InternLM-XC2</td>
            <td>71.83</td>
            <td>5.38</td>
            <td>37.23</td>
            <td>75.80</td>
            <td>9.23</td>
          </tr>
          <tr>
            <td>Shikra</td>
            <td>59.69</td>
            <td>3.25</td>
            <td>13.86</td>
            <td>61.80</td>
            <td>56.65</td>
          </tr>
          <tr>
            <td>LLaVA-RLHF</td>
            <td>59.70</td>
            <td>3.61</td>
            <td>34.59</td>
            <td>61.34</td>
            <td>75.23</td>
          </tr>
          <tr>
            <td>RLHF-V</td>
            <td>64.08</td>
            <td>7.36</td>
            <td>33.69</td>
            <td>69.25</td>
            <td>27.68</td>
          </tr>
    </tbody>
</table>

<script>
    function sortTable(tableId, n) {
        var table, rows, switching, i, x, y, shouldSwitch, dir, switchcount = 0;
        table = document.getElementById(tableId);
        switching = true;
        dir = "asc"; 
        while (switching) {
            switching = false;
            rows = table.rows;
            for (i = 1; i < (rows.length - 1); i++) {
                shouldSwitch = false;
                x = rows[i].getElementsByTagName("TD")[n];
                y = rows[i + 1].getElementsByTagName("TD")[n];
                if (dir == "asc") {
                    if (parseFloat(x.innerHTML) > parseFloat(y.innerHTML)) {
                        shouldSwitch = true;
                        break;
                    }
                } else if (dir == "desc") {
                    if (parseFloat(x.innerHTML) < parseFloat(y.innerHTML)) {
                        shouldSwitch = true;
                        break;
                    }
                }
            }
            if (shouldSwitch) {
                rows[i].parentNode.insertBefore(rows[i + 1], rows[i]);
                switching = true;
                switchcount ++;
            } else {
                if (switchcount == 0 && dir == "asc") {
                    dir = "desc";
                    switching = true;
                }
            }
        }
        setSortingIcon(tableId, n, dir);
    }

    function setSortingIcon(tableId, columnIndex, direction) {
        var headers = document.querySelectorAll("#" + tableId + " th");
        headers.forEach(function(header, index) {
            header.classList.remove("asc", "desc");
            if (index === columnIndex) {
                header.classList.add(direction);
            }
        });
    }
</script>